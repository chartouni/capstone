{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - Scopus and SciVal\n",
    "\n",
    "This notebook performs initial exploration of the Scopus and SciVal data files.\n",
    "\n",
    "## Objectives:\n",
    "1. Load Scopus and SciVal data files\n",
    "2. Examine data structure and schema\n",
    "3. Check for EID column in both datasets\n",
    "4. Identify available features\n",
    "5. Assess data quality and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data.load_data import load_scopus_data, load_scival_data\n",
    "from src.utils.config import config\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "SCOPUS_FILE = '../data/raw/scopus.csv'\nSCIVAL_FILE = '../data/raw/scival.csv'\n\nscopus_df = load_scopus_data(SCOPUS_FILE)\nscival_df = load_scival_data(SCIVAL_FILE)\n\nprint(\"Data files loaded successfully!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examine Scopus Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(f\"Scopus data shape: {scopus_df.shape}\")\nprint(f\"\\nColumns: {list(scopus_df.columns)}\")\nscopus_df.info()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "scopus_df.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check for EID column\nif 'EID' in scopus_df.columns:\n    print(\"✓ EID column found in Scopus data\")\n    print(f\"Unique EIDs: {scopus_df['EID'].nunique()}\")\n    print(f\"Total rows: {len(scopus_df)}\")\n    print(f\"Duplicate EIDs: {scopus_df['EID'].duplicated().sum()}\")\nelse:\n    print(\"✗ EID column NOT found in Scopus data\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examine SciVal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(f\"SciVal data shape: {scival_df.shape}\")\nprint(f\"\\nColumns: {list(scival_df.columns)}\")\nscival_df.info()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "scival_df.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check for EID column\nif 'EID' in scival_df.columns:\n    print(\"✓ EID column found in SciVal data\")\n    print(f\"Unique EIDs: {scival_df['EID'].nunique()}\")\n    print(f\"Total rows: {len(scival_df)}\")\n    print(f\"Duplicate EIDs: {scival_df['EID'].duplicated().sum()}\")\nelse:\n    print(\"✗ EID column NOT found in SciVal data\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identify Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "important_features = ['Abstract', 'Title', 'Citation Count', 'Citations', 'Author', 'Authors', 'h-index', 'Venue', 'Journal', 'Year', 'Publication Year']\n\nprint(\"Scopus columns matching key features:\")\nfor feat in important_features:\n    matching = [col for col in scopus_df.columns if feat.lower() in col.lower()]\n    if matching:\n        print(f\"  {feat}: {matching}\")\n\nprint(\"\\nSciVal columns matching key features:\")\nfor feat in important_features:\n    matching = [col for col in scival_df.columns if feat.lower() in col.lower()]\n    if matching:\n        print(f\"  {feat}: {matching}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"Scopus Missing Values:\")\nscopus_missing = scopus_df.isnull().sum()\nscopus_missing_pct = (scopus_missing / len(scopus_df) * 100).round(2)\nmissing_df = pd.DataFrame({\n    'Missing Count': scopus_missing,\n    'Percentage': scopus_missing_pct\n})\nmissing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"SciVal Missing Values:\")\nscival_missing = scival_df.isnull().sum()\nscival_missing_pct = (scival_missing / len(scival_df) * 100).round(2)\nmissing_df = pd.DataFrame({\n    'Missing Count': scival_missing,\n    'Percentage': scival_missing_pct\n})\nmissing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check EID Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "scopus_eids = set(scopus_df['EID'].dropna())\nscival_eids = set(scival_df['EID'].dropna())\n\ncommon_eids = scopus_eids.intersection(scival_eids)\nonly_scopus = scopus_eids - scival_eids\nonly_scival = scival_eids - scopus_eids\n\nprint(f\"Common EIDs: {len(common_eids)}\")\nprint(f\"Only in Scopus: {len(only_scopus)}\")\nprint(f\"Only in SciVal: {len(only_scival)}\")\nprint(f\"\\nOverlap percentage: {len(common_eids) / min(len(scopus_eids), len(scival_eids)) * 100:.2f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Based on this exploration:\n",
    "1. Proceed to `02_data_merging.ipynb` to merge the datasets\n",
    "2. Identify which columns to keep/drop\n",
    "3. Plan data cleaning strategy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}