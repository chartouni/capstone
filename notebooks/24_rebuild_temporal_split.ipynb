{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuild Temporal Split: 2010-2021\n",
    "\n",
    "New split:\n",
    "- Train: 2010-2017\n",
    "- Test: 2018-2021\n",
    "- Exclude: 2022-2025 (too recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "df = pd.read_pickle('../data/processed/cleaned_data.pkl')\n",
    "print(f\"Total papers: {len(df)}\")\n",
    "\n",
    "# Load all features\n",
    "X = pd.read_pickle('../data/features/X_all.pkl')\n",
    "y_classification = pd.read_pickle('../data/features/y_classification.pkl')\n",
    "y_regression = pd.read_pickle('../data/features/y_regression.pkl')\n",
    "y_regression_log = pd.read_pickle('../data/features/y_regression_log.pkl')\n",
    "metadata = pd.read_pickle('../data/features/metadata.pkl')\n",
    "\n",
    "print(f\"Features: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter to 2010-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only papers from 2010-2021\n",
    "valid_years = list(range(2010, 2022))  # 2010-2021\n",
    "valid_mask = df['Year'].isin(valid_years)\n",
    "\n",
    "print(f\"Papers by year (before filtering):\")\n",
    "print(df['Year'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nPapers to keep (2010-2021): {valid_mask.sum()}\")\n",
    "print(f\"Papers to exclude (2022-2025): {(~valid_mask).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filter All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter all datasets\n",
    "X_filtered = X[valid_mask]\n",
    "y_class_filtered = y_classification[valid_mask]\n",
    "y_reg_filtered = y_regression[valid_mask]\n",
    "y_reg_log_filtered = y_regression_log[valid_mask]\n",
    "metadata_filtered = metadata[valid_mask]\n",
    "df_filtered = df[valid_mask]\n",
    "\n",
    "print(f\"Filtered dataset: {len(X_filtered)} papers\")\n",
    "print(f\"\\nYear distribution (after filtering):\")\n",
    "print(df_filtered['Year'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create New Temporal Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New temporal split\n",
    "train_years = list(range(2010, 2018))  # 2010-2017\n",
    "test_years = list(range(2018, 2022))   # 2018-2021\n",
    "\n",
    "train_mask = df_filtered['Year'].isin(train_years)\n",
    "test_mask = df_filtered['Year'].isin(test_years)\n",
    "\n",
    "# Split features\n",
    "X_train_temporal = X_filtered[train_mask]\n",
    "X_test_temporal = X_filtered[test_mask]\n",
    "\n",
    "# Split classification targets\n",
    "y_train_cls_temporal = y_class_filtered[train_mask]\n",
    "y_test_cls_temporal = y_class_filtered[test_mask]\n",
    "\n",
    "# Split regression targets\n",
    "y_train_reg_temporal = y_reg_log_filtered[train_mask]\n",
    "y_test_reg_temporal = y_reg_log_filtered[test_mask]\n",
    "\n",
    "# Split metadata\n",
    "metadata_train = metadata_filtered[train_mask]\n",
    "metadata_test = metadata_filtered[test_mask]\n",
    "\n",
    "print(f\"=\"*60)\n",
    "print(\"NEW TEMPORAL SPLIT\")\n",
    "print(f\"=\"*60)\n",
    "print(f\"\\nTrain (2010-2017): {len(X_train_temporal)} papers\")\n",
    "print(f\"Test (2018-2021): {len(X_test_temporal)} papers\")\n",
    "print(f\"Total: {len(X_train_temporal) + len(X_test_temporal)} papers\")\n",
    "\n",
    "print(f\"\\nTrain years:\")\n",
    "print(df_filtered[train_mask]['Year'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nTest years:\")\n",
    "print(df_filtered[test_mask]['Year'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validate Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Validation checks:\")\n",
    "print(f\"  Train + Test = Total: {len(X_train_temporal) + len(X_test_temporal) == len(X_filtered)}\")\n",
    "\n",
    "# Check for overlap\n",
    "train_indices = set(X_train_temporal.index)\n",
    "test_indices = set(X_test_temporal.index)\n",
    "overlap = train_indices & test_indices\n",
    "print(f\"  No overlap: {len(overlap) == 0}\")\n",
    "\n",
    "# Check target distributions\n",
    "print(f\"\\nClassification targets:\")\n",
    "print(f\"  Train high-impact: {y_train_cls_temporal.sum()} ({y_train_cls_temporal.mean()*100:.1f}%)\")\n",
    "print(f\"  Test high-impact: {y_test_cls_temporal.sum()} ({y_test_cls_temporal.mean()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nRegression targets (log-transformed):\")\n",
    "print(f\"  Train mean: {y_train_reg_temporal.mean():.2f}\")\n",
    "print(f\"  Test mean: {y_test_reg_temporal.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save New Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('../data/features')\n",
    "\n",
    "# Save temporal splits\n",
    "X_train_temporal.to_pickle(output_dir / 'X_train_temporal.pkl')\n",
    "X_test_temporal.to_pickle(output_dir / 'X_test_temporal.pkl')\n",
    "y_train_cls_temporal.to_pickle(output_dir / 'y_train_cls_temporal.pkl')\n",
    "y_test_cls_temporal.to_pickle(output_dir / 'y_test_cls_temporal.pkl')\n",
    "y_train_reg_temporal.to_pickle(output_dir / 'y_train_reg_temporal.pkl')\n",
    "y_test_reg_temporal.to_pickle(output_dir / 'y_test_reg_temporal.pkl')\n",
    "metadata_train.to_pickle(output_dir / 'metadata_train.pkl')\n",
    "metadata_test.to_pickle(output_dir / 'metadata_test.pkl')\n",
    "\n",
    "print(\"âœ“ All temporal split files saved!\")\n",
    "print(f\"\\nSaved to: {output_dir}\")\n",
    "print(\"  - X_train_temporal.pkl\")\n",
    "print(\"  - X_test_temporal.pkl\")\n",
    "print(\"  - y_train_cls_temporal.pkl\")\n",
    "print(\"  - y_test_cls_temporal.pkl\")\n",
    "print(\"  - y_train_reg_temporal.pkl\")\n",
    "print(\"  - y_test_reg_temporal.pkl\")\n",
    "print(\"  - metadata_train.pkl\")\n",
    "print(\"  - metadata_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TEMPORAL SPLIT REBUILT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOld split (2015-2020): {2545 + 3573} papers\")\n",
    "print(f\"New split (2010-2021): {len(X_train_temporal) + len(X_test_temporal)} papers\")\n",
    "print(f\"\\nAdded papers: {len(X_train_temporal) + len(X_test_temporal) - (2545 + 3573)}\")\n",
    "print(f\"\\nExcluded (2022-2025): {len(df) - len(df_filtered)} papers\")\n",
    "print(f\"\\nReady for model retraining!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
