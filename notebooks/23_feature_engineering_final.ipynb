{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Feature Engineering\n",
    "\n",
    "Combine all features and create final dataset:\n",
    "1. Load all feature sets\n",
    "2. Combine features\n",
    "3. Add metadata and target\n",
    "4. Create train/test splits\n",
    "5. Save final datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "feature_dir = Path('../data/features')\n\ntext_features = pd.read_pickle(feature_dir / 'text_features.pkl')\nvenue_features = pd.read_pickle(feature_dir / 'venue_features.pkl')\nauthor_features = pd.read_pickle(feature_dir / 'author_features.pkl')\n\n# Load title features if available\ntry:\n    title_features = pd.read_pickle(feature_dir / 'title_features.pkl')\n    has_title_features = True\nexcept FileNotFoundError:\n    title_features = None\n    has_title_features = False\n\n# Load additional features if available\ntry:\n    additional_features = pd.read_pickle(feature_dir / 'additional_features.pkl')\n    has_additional_features = True\nexcept FileNotFoundError:\n    additional_features = None\n    has_additional_features = False\n\nprint(f\"Text features (abstract): {text_features.shape}\")\nif has_title_features:\n    print(f\"Text features (title): {title_features.shape}\")\nprint(f\"Venue features: {venue_features.shape}\")\nprint(f\"Author features: {author_features.shape}\")\nif has_additional_features:\n    print(f\"Additional features: {additional_features.shape}\")\n    \nif not has_title_features:\n    print(\"Title features: Not found (run notebook 20b first)\")\nif not has_additional_features:\n    print(\"Additional features: Not found (run notebook 22b first)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Cleaned Data for Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/processed/cleaned_data.pkl')\n",
    "print(f\"Cleaned data: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Combine All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Combine all features\nfeature_list = [text_features, venue_features, author_features]\n\nif title_features is not None:\n    feature_list.append(title_features)\n    \nif additional_features is not None:\n    feature_list.append(additional_features)\n\nX = pd.concat(feature_list, axis=1)\n\nprint(f\"Combined features shape: {X.shape}\")\nprint(f\"Total features: {X.shape[1]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add Metadata and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = df[['EID', 'Title', 'Year', 'Scopus Source title']].copy()\n",
    "\n",
    "y_regression = df['Citations'].copy()\n",
    "y_regression_log = np.log1p(y_regression)\n",
    "\n",
    "threshold = y_regression.quantile(0.75)\n",
    "y_classification = (y_regression >= threshold).astype(int)\n",
    "\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"Citations range: {y_regression.min()} - {y_regression.max()}\")\n",
    "print(f\"Median citations: {y_regression.median():.0f}\")\n",
    "print(f\"Top 25% threshold: {threshold:.0f}\")\n",
    "print(f\"High-impact papers: {y_classification.sum()} ({y_classification.mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Temporal Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_years = [2015, 2016, 2017]\n",
    "test_years = [2018, 2019, 2020]\n",
    "\n",
    "train_mask = df['Year'].isin(train_years)\n",
    "test_mask = df['Year'].isin(test_years)\n",
    "\n",
    "X_train_temporal = X[train_mask]\n",
    "X_test_temporal = X[test_mask]\n",
    "y_train_cls_temporal = y_classification[train_mask]\n",
    "y_test_cls_temporal = y_classification[test_mask]\n",
    "y_train_reg_temporal = y_regression_log[train_mask]\n",
    "y_test_reg_temporal = y_regression_log[test_mask]\n",
    "metadata_train = metadata[train_mask]\n",
    "metadata_test = metadata[test_mask]\n",
    "\n",
    "print(f\"\\nTemporal split:\")\n",
    "print(f\"Train (2015-2017): {X_train_temporal.shape[0]} papers\")\n",
    "print(f\"Test (2018-2020): {X_test_temporal.shape[0]} papers\")\n",
    "print(f\"\\nTrain high-impact: {y_train_cls_temporal.sum()} ({y_train_cls_temporal.mean()*100:.1f}%)\")\n",
    "print(f\"Test high-impact: {y_test_cls_temporal.sum()} ({y_test_cls_temporal.mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('../data/features')\n",
    "\n",
    "X.to_pickle(output_dir / 'X_all.pkl')\n",
    "y_classification.to_pickle(output_dir / 'y_classification.pkl')\n",
    "y_regression.to_pickle(output_dir / 'y_regression.pkl')\n",
    "y_regression_log.to_pickle(output_dir / 'y_regression_log.pkl')\n",
    "metadata.to_pickle(output_dir / 'metadata.pkl')\n",
    "\n",
    "X_train_temporal.to_pickle(output_dir / 'X_train_temporal.pkl')\n",
    "X_test_temporal.to_pickle(output_dir / 'X_test_temporal.pkl')\n",
    "y_train_cls_temporal.to_pickle(output_dir / 'y_train_cls_temporal.pkl')\n",
    "y_test_cls_temporal.to_pickle(output_dir / 'y_test_cls_temporal.pkl')\n",
    "y_train_reg_temporal.to_pickle(output_dir / 'y_train_reg_temporal.pkl')\n",
    "y_test_reg_temporal.to_pickle(output_dir / 'y_test_reg_temporal.pkl')\n",
    "metadata_train.to_pickle(output_dir / 'metadata_train.pkl')\n",
    "metadata_test.to_pickle(output_dir / 'metadata_test.pkl')\n",
    "\n",
    "print(\"All datasets saved to data/features/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 60)\nprint(\"FINAL FEATURE ENGINEERING SUMMARY\")\nprint(\"=\" * 60)\nprint(f\"Total papers: {len(X)}\")\nprint(f\"Total features: {X.shape[1]}\")\nprint(f\"  - Text features from abstracts: {text_features.shape[1]}\")\nif title_features is not None:\n    print(f\"  - Text features from titles: {title_features.shape[1]}\")\nprint(f\"  - Venue features: {venue_features.shape[1]}\")\nprint(f\"  - Author features: {author_features.shape[1]}\")\nif additional_features is not None:\n    print(f\"  - Additional features: {additional_features.shape[1]}\")\nprint(f\"\\nTargets:\")\nprint(f\"  - Classification: Top {threshold:.0f} citations (25%)\")\nprint(f\"  - Regression: Log-transformed citation counts\")\nprint(f\"\\nTemporal validation:\")\nprint(f\"  - Train: {X_train_temporal.shape[0]} papers (2015-2017)\")\nprint(f\"  - Test: {X_test_temporal.shape[0]} papers (2018-2020)\")\nprint(f\"\\nReady for modeling!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}