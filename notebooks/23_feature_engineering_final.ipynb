{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Feature Engineering\n",
    "\n",
    "Combine all features and create final dataset:\n",
    "1. Load all feature sets\n",
    "2. Combine features\n",
    "3. Add metadata and target\n",
    "4. Create train/test splits\n",
    "5. Save final datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text features: (14832, 5000)\n",
      "Venue features: (14832, 9)\n",
      "Author features: (14832, 10)\n"
     ]
    }
   ],
   "source": [
    "feature_dir = Path('../data/features')\n",
    "\n",
    "text_features = pd.read_pickle(feature_dir / 'text_features.pkl')\n",
    "venue_features = pd.read_pickle(feature_dir / 'venue_features.pkl')\n",
    "author_features = pd.read_pickle(feature_dir / 'author_features.pkl')\n",
    "\n",
    "print(f\"Text features: {text_features.shape}\")\n",
    "print(f\"Venue features: {venue_features.shape}\")\n",
    "print(f\"Author features: {author_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Cleaned Data for Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data: (14832, 68)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/processed/cleaned_data.pkl')\n",
    "print(f\"Cleaned data: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Combine All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features shape: (14832, 5019)\n",
      "Total features: 5019\n"
     ]
    }
   ],
   "source": [
    "X = pd.concat([\n",
    "    text_features,\n",
    "    venue_features,\n",
    "    author_features\n",
    "], axis=1)\n",
    "\n",
    "print(f\"Combined features shape: {X.shape}\")\n",
    "print(f\"Total features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add Metadata and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target statistics:\n",
      "Citations range: 0 - 66291\n",
      "Median citations: 10\n",
      "Top 25% threshold: 26\n",
      "High-impact papers: 3780 (25.5%)\n"
     ]
    }
   ],
   "source": [
    "metadata = df[['EID', 'Title', 'Year', 'Scopus Source title']].copy()\n",
    "\n",
    "y_regression = df['Citations'].copy()\n",
    "y_regression_log = np.log1p(y_regression)\n",
    "\n",
    "threshold = y_regression.quantile(0.75)\n",
    "y_classification = (y_regression >= threshold).astype(int)\n",
    "\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"Citations range: {y_regression.min()} - {y_regression.max()}\")\n",
    "print(f\"Median citations: {y_regression.median():.0f}\")\n",
    "print(f\"Top 25% threshold: {threshold:.0f}\")\n",
    "print(f\"High-impact papers: {y_classification.sum()} ({y_classification.mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Temporal Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temporal split:\n",
      "Train (2015-2017): 2545 papers\n",
      "Test (2018-2020): 3573 papers\n",
      "\n",
      "Train high-impact: 941 (37.0%)\n",
      "Test high-impact: 1068 (29.9%)\n"
     ]
    }
   ],
   "source": [
    "train_years = [2015, 2016, 2017]\n",
    "test_years = [2018, 2019, 2020]\n",
    "\n",
    "train_mask = df['Year'].isin(train_years)\n",
    "test_mask = df['Year'].isin(test_years)\n",
    "\n",
    "X_train_temporal = X[train_mask]\n",
    "X_test_temporal = X[test_mask]\n",
    "y_train_cls_temporal = y_classification[train_mask]\n",
    "y_test_cls_temporal = y_classification[test_mask]\n",
    "y_train_reg_temporal = y_regression_log[train_mask]\n",
    "y_test_reg_temporal = y_regression_log[test_mask]\n",
    "metadata_train = metadata[train_mask]\n",
    "metadata_test = metadata[test_mask]\n",
    "\n",
    "print(f\"\\nTemporal split:\")\n",
    "print(f\"Train (2015-2017): {X_train_temporal.shape[0]} papers\")\n",
    "print(f\"Test (2018-2020): {X_test_temporal.shape[0]} papers\")\n",
    "print(f\"\\nTrain high-impact: {y_train_cls_temporal.sum()} ({y_train_cls_temporal.mean()*100:.1f}%)\")\n",
    "print(f\"Test high-impact: {y_test_cls_temporal.sum()} ({y_test_cls_temporal.mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets saved to data/features/\n"
     ]
    }
   ],
   "source": [
    "output_dir = Path('../data/features')\n",
    "\n",
    "X.to_pickle(output_dir / 'X_all.pkl')\n",
    "y_classification.to_pickle(output_dir / 'y_classification.pkl')\n",
    "y_regression.to_pickle(output_dir / 'y_regression.pkl')\n",
    "y_regression_log.to_pickle(output_dir / 'y_regression_log.pkl')\n",
    "metadata.to_pickle(output_dir / 'metadata.pkl')\n",
    "\n",
    "X_train_temporal.to_pickle(output_dir / 'X_train_temporal.pkl')\n",
    "X_test_temporal.to_pickle(output_dir / 'X_test_temporal.pkl')\n",
    "y_train_cls_temporal.to_pickle(output_dir / 'y_train_cls_temporal.pkl')\n",
    "y_test_cls_temporal.to_pickle(output_dir / 'y_test_cls_temporal.pkl')\n",
    "y_train_reg_temporal.to_pickle(output_dir / 'y_train_reg_temporal.pkl')\n",
    "y_test_reg_temporal.to_pickle(output_dir / 'y_test_reg_temporal.pkl')\n",
    "metadata_train.to_pickle(output_dir / 'metadata_train.pkl')\n",
    "metadata_test.to_pickle(output_dir / 'metadata_test.pkl')\n",
    "\n",
    "print(\"All datasets saved to data/features/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL FEATURE ENGINEERING SUMMARY\n",
      "============================================================\n",
      "Total papers: 14832\n",
      "Total features: 5019\n",
      "  - Text features (TF-IDF): 5000\n",
      "  - Venue features: 9\n",
      "  - Author features: 10\n",
      "\n",
      "Targets:\n",
      "  - Classification: Top 26 citations (25%)\n",
      "  - Regression: Log-transformed citation counts\n",
      "\n",
      "Temporal validation:\n",
      "  - Train: 2545 papers (2015-2017)\n",
      "  - Test: 3573 papers (2018-2020)\n",
      "\n",
      "Ready for modeling!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FINAL FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total papers: {len(X)}\")\n",
    "print(f\"Total features: {X.shape[1]}\")\n",
    "print(f\"  - Text features (TF-IDF): {text_features.shape[1]}\")\n",
    "print(f\"  - Venue features: {venue_features.shape[1]}\")\n",
    "print(f\"  - Author features: {author_features.shape[1]}\")\n",
    "print(f\"\\nTargets:\")\n",
    "print(f\"  - Classification: Top {threshold:.0f} citations (25%)\")\n",
    "print(f\"  - Regression: Log-transformed citation counts\")\n",
    "print(f\"\\nTemporal validation:\")\n",
    "print(f\"  - Train: {X_train_temporal.shape[0]} papers (2015-2017)\")\n",
    "print(f\"  - Test: {X_test_temporal.shape[0]} papers (2018-2020)\")\n",
    "print(f\"\\nReady for modeling!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
