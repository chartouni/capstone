{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation Prediction with Unsupervised Feature Discovery\n",
    "\n",
    "**Goal**: Predict paper citation counts using supervised learning + unsupervised feature engineering\n",
    "\n",
    "**Pipeline**:\n",
    "1. Load data (papers from MIT, Stanford, Berkeley, Michigan, Georgia Tech, Toronto)\n",
    "2. Exploratory Data Analysis\n",
    "3. Unsupervised Feature Discovery:\n",
    "   - Topic modeling (LDA)\n",
    "   - University clustering\n",
    "   - Abstract embeddings + PCA\n",
    "4. Feature Engineering\n",
    "5. Supervised Models (Random Forest, XGBoost)\n",
    "6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy scikit-learn matplotlib seaborn\n",
    "!pip install sentence-transformers transformers\n",
    "!pip install xgboost lightgbm\n",
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import LatentDirichletAllocation, PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Expected columns:\n",
    "- `title`: Paper title\n",
    "- `abstract`: Paper abstract\n",
    "- `authors`: Author names (comma-separated or list)\n",
    "- `university`: University name\n",
    "- `venue`: Conference/journal name\n",
    "- `year`: Publication year\n",
    "- `citations`: Citation count (target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data here\n",
    "# df = pd.read_csv('papers_dataset.csv')\n",
    "\n",
    "# For now, create dummy data to test the pipeline\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "universities = ['MIT', 'Stanford', 'UC Berkeley', 'University of Michigan', \n",
    "                'Georgia Tech', 'University of Toronto']\n",
    "venues = ['NeurIPS', 'ICML', 'CVPR', 'ICCV', 'ACL', 'EMNLP', 'SIGIR', 'KDD']\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'title': [f'Paper {i}' for i in range(n_samples)],\n",
    "    'abstract': [f'This paper presents a novel approach to machine learning using deep neural networks and optimization techniques.' for _ in range(n_samples)],\n",
    "    'authors': [f'Author{i}, Author{i+1}' for i in range(n_samples)],\n",
    "    'university': np.random.choice(universities, n_samples),\n",
    "    'venue': np.random.choice(venues, n_samples),\n",
    "    'year': np.random.randint(2015, 2021, n_samples),\n",
    "    'citations': np.random.lognormal(3, 1.5, n_samples).astype(int)\n",
    "})\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nCitation statistics:\")\n",
    "print(df['citations'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Citation distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(df['citations'], bins=50, edgecolor='black')\n",
    "axes[0].set_xlabel('Citations')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Citation Distribution')\n",
    "\n",
    "axes[1].hist(np.log1p(df['citations']), bins=50, edgecolor='black', color='orange')\n",
    "axes[1].set_xlabel('Log(Citations + 1)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Log-Transformed Citation Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Citations by university\n",
    "plt.figure(figsize=(12, 6))\n",
    "df.groupby('university')['citations'].mean().sort_values().plot(kind='barh')\n",
    "plt.xlabel('Average Citations')\n",
    "plt.title('Average Citations by University')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Citations by venue\n",
    "plt.figure(figsize=(12, 6))\n",
    "df.groupby('venue')['citations'].mean().sort_values().plot(kind='barh', color='green')\n",
    "plt.xlabel('Average Citations')\n",
    "plt.title('Average Citations by Venue')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Citations by year\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.groupby('year')['citations'].mean().plot(marker='o', linewidth=2)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Citations')\n",
    "plt.title('Average Citations by Publication Year')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unsupervised Feature Discovery\n",
    "\n",
    "### 3.1 Topic Modeling (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modeling on abstracts\n",
    "print(\"Running LDA topic modeling...\")\n",
    "\n",
    "# Vectorize abstracts\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=1000,\n",
    "    stop_words='english',\n",
    "    min_df=2,\n",
    "    max_df=0.8\n",
    ")\n",
    "\n",
    "X_counts = vectorizer.fit_transform(df['abstract'])\n",
    "\n",
    "# LDA with 15 topics\n",
    "n_topics = 15\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    max_iter=20\n",
    ")\n",
    "\n",
    "topic_distributions = lda.fit_transform(X_counts)\n",
    "\n",
    "print(f\"Topic distributions shape: {topic_distributions.shape}\")\n",
    "print(\"\\nTop words per topic:\")\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    top_words = [feature_names[i] for i in topic.argsort()[-10:][::-1]]\n",
    "    print(f\"Topic {topic_idx}: {', '.join(top_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add topic features to dataframe\n",
    "topic_cols = [f'topic_{i}' for i in range(n_topics)]\n",
    "df_topics = pd.DataFrame(topic_distributions, columns=topic_cols)\n",
    "df = pd.concat([df.reset_index(drop=True), df_topics], axis=1)\n",
    "\n",
    "# Dominant topic\n",
    "df['dominant_topic'] = topic_distributions.argmax(axis=1)\n",
    "\n",
    "print(\"Topic features added!\")\n",
    "print(f\"New shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize citations by dominant topic\n",
    "plt.figure(figsize=(12, 6))\n",
    "df.groupby('dominant_topic')['citations'].mean().plot(kind='bar')\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Average Citations')\n",
    "plt.title('Average Citations by Dominant Topic')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 University Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster universities based on citation patterns\n",
    "print(\"Clustering universities...\")\n",
    "\n",
    "university_stats = df.groupby('university')['citations'].agg(['mean', 'std', 'median', 'count'])\n",
    "print(\"\\nUniversity statistics:\")\n",
    "print(university_stats)\n",
    "\n",
    "# K-means clustering (3 tiers: top, mid, lower)\n",
    "n_university_clusters = 3\n",
    "kmeans_uni = KMeans(n_clusters=n_university_clusters, random_state=42)\n",
    "university_stats['cluster'] = kmeans_uni.fit_predict(university_stats[['mean', 'std']])\n",
    "\n",
    "# Map back to dataframe\n",
    "university_to_cluster = university_stats['cluster'].to_dict()\n",
    "df['university_tier'] = df['university'].map(university_to_cluster)\n",
    "\n",
    "print(\"\\nUniversity clusters:\")\n",
    "print(university_stats[['mean', 'cluster']].sort_values('cluster'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Venue Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster venues based on citation patterns\n",
    "print(\"Clustering venues...\")\n",
    "\n",
    "venue_stats = df.groupby('venue')['citations'].agg(['mean', 'std', 'median', 'count'])\n",
    "print(\"\\nVenue statistics:\")\n",
    "print(venue_stats)\n",
    "\n",
    "# K-means clustering\n",
    "n_venue_clusters = 3\n",
    "kmeans_venue = KMeans(n_clusters=n_venue_clusters, random_state=42)\n",
    "venue_stats['cluster'] = kmeans_venue.fit_predict(venue_stats[['mean', 'std']])\n",
    "\n",
    "# Map back to dataframe\n",
    "venue_to_cluster = venue_stats['cluster'].to_dict()\n",
    "df['venue_tier'] = df['venue'].map(venue_to_cluster)\n",
    "\n",
    "print(\"\\nVenue clusters:\")\n",
    "print(venue_stats[['mean', 'cluster']].sort_values('cluster'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Abstract Embeddings + Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings using SciBERT\n",
    "print(\"Generating abstract embeddings with SciBERT...\")\n",
    "print(\"(This may take a few minutes)\")\n",
    "\n",
    "model = SentenceTransformer('allenai/scibert_scivocab_uncased')\n",
    "\n",
    "# Generate embeddings (batch processing for efficiency)\n",
    "embeddings = model.encode(\n",
    "    df['abstract'].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA dimensionality reduction\n",
    "print(\"Reducing dimensionality with PCA...\")\n",
    "\n",
    "n_pca_components = 50\n",
    "pca = PCA(n_components=n_pca_components, random_state=42)\n",
    "embeddings_pca = pca.fit_transform(embeddings)\n",
    "\n",
    "print(f\"Reduced embeddings shape: {embeddings_pca.shape}\")\n",
    "print(f\"Explained variance ratio (first 10 components): {pca.explained_variance_ratio_[:10]}\")\n",
    "print(f\"Total explained variance: {pca.explained_variance_ratio_.sum():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add PCA features to dataframe\n",
    "pca_cols = [f'pca_{i}' for i in range(n_pca_components)]\n",
    "df_pca = pd.DataFrame(embeddings_pca, columns=pca_cols)\n",
    "df = pd.concat([df.reset_index(drop=True), df_pca], axis=1)\n",
    "\n",
    "print(\"PCA features added!\")\n",
    "print(f\"Final shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional features\n",
    "print(\"Creating additional features...\")\n",
    "\n",
    "# Text-based features\n",
    "df['abstract_length'] = df['abstract'].str.len()\n",
    "df['abstract_word_count'] = df['abstract'].str.split().str.len()\n",
    "df['title_length'] = df['title'].str.len()\n",
    "\n",
    "# Author features\n",
    "df['num_authors'] = df['authors'].str.count(',') + 1\n",
    "\n",
    "# Time features\n",
    "df['years_since_pub'] = 2026 - df['year']\n",
    "\n",
    "print(\"Features created!\")\n",
    "df[['abstract_length', 'abstract_word_count', 'num_authors', 'years_since_pub']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "le_university = LabelEncoder()\n",
    "le_venue = LabelEncoder()\n",
    "\n",
    "df['university_encoded'] = le_university.fit_transform(df['university'])\n",
    "df['venue_encoded'] = le_venue.fit_transform(df['venue'])\n",
    "\n",
    "print(\"Categorical encoding complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "### 5.1 Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "feature_cols = (\n",
    "    # Basic features\n",
    "    ['abstract_length', 'abstract_word_count', 'title_length', 'num_authors', \n",
    "     'years_since_pub', 'year'] +\n",
    "    # Categorical encoded\n",
    "    ['university_encoded', 'venue_encoded'] +\n",
    "    # Unsupervised features - clusters\n",
    "    ['university_tier', 'venue_tier', 'dominant_topic'] +\n",
    "    # Unsupervised features - topics\n",
    "    topic_cols +\n",
    "    # Unsupervised features - PCA\n",
    "    pca_cols\n",
    ")\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['citations']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTotal features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Baseline: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Random Forest...\")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf_train = rf.predict(X_train)\n",
    "y_pred_rf_test = rf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n=== Random Forest Results ===\")\n",
    "print(f\"Train RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_rf_train)):.2f}\")\n",
    "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rf_test)):.2f}\")\n",
    "print(f\"Train MAE: {mean_absolute_error(y_train, y_pred_rf_train):.2f}\")\n",
    "print(f\"Test MAE: {mean_absolute_error(y_test, y_pred_rf_test):.2f}\")\n",
    "print(f\"Train R¬≤: {r2_score(y_train, y_pred_rf_train):.3f}\")\n",
    "print(f\"Test R¬≤: {r2_score(y_test, y_pred_rf_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "print(feature_importance.head(20))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_importance.head(20).plot(x='feature', y='importance', kind='barh')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training XGBoost...\")\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb_train = xgb_model.predict(X_train)\n",
    "y_pred_xgb_test = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n=== XGBoost Results ===\")\n",
    "print(f\"Train RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_xgb_train)):.2f}\")\n",
    "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_xgb_test)):.2f}\")\n",
    "print(f\"Train MAE: {mean_absolute_error(y_train, y_pred_xgb_train):.2f}\")\n",
    "print(f\"Test MAE: {mean_absolute_error(y_test, y_pred_xgb_test):.2f}\")\n",
    "print(f\"Train R¬≤: {r2_score(y_train, y_pred_xgb_train):.3f}\")\n",
    "print(f\"Test R¬≤: {r2_score(y_test, y_pred_xgb_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Random Forest\n",
    "axes[0].scatter(y_test, y_pred_rf_test, alpha=0.5)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Citations')\n",
    "axes[0].set_ylabel('Predicted Citations')\n",
    "axes[0].set_title(f'Random Forest (R¬≤ = {r2_score(y_test, y_pred_rf_test):.3f})')\n",
    "\n",
    "# XGBoost\n",
    "axes[1].scatter(y_test, y_pred_xgb_test, alpha=0.5, color='green')\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Actual Citations')\n",
    "axes[1].set_ylabel('Predicted Citations')\n",
    "axes[1].set_title(f'XGBoost (R¬≤ = {r2_score(y_test, y_pred_xgb_test):.3f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Random Forest residuals\n",
    "residuals_rf = y_test - y_pred_rf_test\n",
    "axes[0].scatter(y_pred_rf_test, residuals_rf, alpha=0.5)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[0].set_xlabel('Predicted Citations')\n",
    "axes[0].set_ylabel('Residuals')\n",
    "axes[0].set_title('Random Forest Residuals')\n",
    "\n",
    "# XGBoost residuals\n",
    "residuals_xgb = y_test - y_pred_xgb_test\n",
    "axes[1].scatter(y_pred_xgb_test, residuals_xgb, alpha=0.5, color='green')\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Citations')\n",
    "axes[1].set_ylabel('Residuals')\n",
    "axes[1].set_title('XGBoost Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison summary\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'XGBoost'],\n",
    "    'Test RMSE': [\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_rf_test)),\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_xgb_test))\n",
    "    ],\n",
    "    'Test MAE': [\n",
    "        mean_absolute_error(y_test, y_pred_rf_test),\n",
    "        mean_absolute_error(y_test, y_pred_xgb_test)\n",
    "    ],\n",
    "    'Test R¬≤': [\n",
    "        r2_score(y_test, y_pred_rf_test),\n",
    "        r2_score(y_test, y_pred_xgb_test)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(comparison)\n",
    "\n",
    "# Determine best model\n",
    "best_model_idx = comparison['Test R¬≤'].idxmax()\n",
    "best_model = comparison.loc[best_model_idx, 'Model']\n",
    "print(f\"\\nüèÜ Best Model: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Group Analysis\n",
    "\n",
    "Analyze the contribution of unsupervised features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model without unsupervised features\n",
    "basic_features = ['abstract_length', 'abstract_word_count', 'title_length', \n",
    "                  'num_authors', 'years_since_pub', 'year',\n",
    "                  'university_encoded', 'venue_encoded']\n",
    "\n",
    "X_train_basic = X_train[basic_features]\n",
    "X_test_basic = X_test[basic_features]\n",
    "\n",
    "rf_basic = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_basic.fit(X_train_basic, y_train)\n",
    "y_pred_basic = rf_basic.predict(X_test_basic)\n",
    "\n",
    "print(\"=== Baseline (No Unsupervised Features) ===\")\n",
    "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_basic)):.2f}\")\n",
    "print(f\"Test R¬≤: {r2_score(y_test, y_pred_basic):.3f}\")\n",
    "\n",
    "print(\"\\n=== Full Model (With Unsupervised Features) ===\")\n",
    "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rf_test)):.2f}\")\n",
    "print(f\"Test R¬≤: {r2_score(y_test, y_pred_rf_test):.3f}\")\n",
    "\n",
    "improvement = r2_score(y_test, y_pred_rf_test) - r2_score(y_test, y_pred_basic)\n",
    "print(f\"\\n‚úÖ R¬≤ Improvement from Unsupervised Features: {improvement:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save best model and preprocessing objects\n",
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf if best_model == 'Random Forest' else xgb_model, f)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open('encoders.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'university': le_university,\n",
    "        'venue': le_venue,\n",
    "        'vectorizer': vectorizer,\n",
    "        'lda': lda,\n",
    "        'pca': pca,\n",
    "        'sentence_model': model\n",
    "    }, f)\n",
    "\n",
    "print(\"Models and preprocessors saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. ‚úÖ **Unsupervised feature discovery** using LDA, clustering, and embeddings\n",
    "2. ‚úÖ **Feature engineering** from discovered patterns\n",
    "3. ‚úÖ **Supervised prediction** using Random Forest and XGBoost\n",
    "4. ‚úÖ **Evaluation** showing improvement from unsupervised features\n",
    "\n",
    "**Next steps**:\n",
    "- Load real data from your professor\n",
    "- Tune hyperparameters with grid search\n",
    "- Try additional models (LightGBM, neural networks)\n",
    "- Feature selection to reduce dimensionality\n",
    "- Cross-validation for robust evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
