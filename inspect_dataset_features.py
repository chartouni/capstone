"""
Inspect Features in Cleaned Dataset
Shows all columns and features used for model training
"""

import pandas as pd
import pickle
from pathlib import Path

print("="*80)
print("CLEANED DATASET FEATURE INSPECTION")
print("="*80)

# 1. CLEANED DATA
print("\n1. CLEANED DATA (data/processed/cleaned_data.pkl)")
print("-"*80)

try:
    df = pd.read_pickle('data/processed/cleaned_data.pkl')
    print(f"‚úì Loaded: {df.shape[0]} rows √ó {df.shape[1]} columns")
    print(f"\nAll columns in cleaned_data.pkl:")
    for i, col in enumerate(df.columns, 1):
        print(f"  {i:2d}. {col}")
except Exception as e:
    print(f"‚úó Error: {e}")

# 2. ENGINEERED FEATURES
print("\n\n2. ENGINEERED FEATURES (data/features/X_all.pkl)")
print("-"*80)

try:
    X = pd.read_pickle('data/features/X_all.pkl')
    print(f"‚úì Loaded: {X.shape[0]} rows √ó {X.shape[1]} features")

    # Categorize features
    venue_cols = [col for col in X.columns if any(x in str(col).lower() for x in ['snip', 'citescore', 'sjr', 'venue', 'journal', 'percentile', 'composite', 'top_journal'])]

    author_cols = [col for col in X.columns if any(x in str(col).lower() for x in ['author', 'institution', 'team', 'collab', 'countries', 'country', 'single_author', 'international'])]

    text_cols = [col for col in X.columns if str(col).startswith('tfidf_')]

    other_cols = [col for col in X.columns if col not in venue_cols and col not in author_cols and col not in text_cols]

    # Display breakdown
    print(f"\nüìä FEATURE BREAKDOWN:")
    print(f"  ‚Ä¢ Venue features: {len(venue_cols)}")
    print(f"  ‚Ä¢ Author features: {len(author_cols)}")
    print(f"  ‚Ä¢ Text features (TF-IDF): {len(text_cols)}")
    print(f"  ‚Ä¢ Other features: {len(other_cols)}")
    print(f"  ‚Ä¢ TOTAL: {len(X.columns)}")

    # Show venue features
    print(f"\nüèõÔ∏è VENUE FEATURES ({len(venue_cols)}):")
    for col in venue_cols:
        print(f"    {col}")

    # Show author features
    print(f"\nüë• AUTHOR FEATURES ({len(author_cols)}):")
    for col in author_cols:
        print(f"    {col}")

    # Show sample text features
    print(f"\nüìù TEXT FEATURES (TF-IDF): {len(text_cols)} total")
    print(f"    Sample (first 30):")
    for col in text_cols[:30]:
        print(f"      {col}")
    if len(text_cols) > 30:
        print(f"      ... and {len(text_cols) - 30} more TF-IDF features")

    # Show other features if any
    if other_cols:
        print(f"\n‚ùì OTHER FEATURES ({len(other_cols)}):")
        for col in other_cols:
            print(f"    {col}")

except Exception as e:
    print(f"‚úó Error: {e}")

# 3. INDIVIDUAL FEATURE FILES
print("\n\n3. INDIVIDUAL FEATURE FILES")
print("-"*80)

feature_files = [
    ('data/features/venue_features.pkl', 'Venue Features'),
    ('data/features/author_features.pkl', 'Author Features'),
    ('data/features/text_features.pkl', 'Text Features (TF-IDF)'),
]

for filepath, name in feature_files:
    print(f"\n{name} ({filepath}):")
    try:
        features = pd.read_pickle(filepath)
        print(f"  ‚úì Shape: {features.shape[0]} rows √ó {features.shape[1]} features")
        print(f"  Columns:")
        for col in features.columns:
            print(f"    ‚Ä¢ {col}")
    except FileNotFoundError:
        print(f"  ‚úó File not found")
    except Exception as e:
        print(f"  ‚úó Error: {e}")

# 4. TEMPORAL SPLITS
print("\n\n4. TEMPORAL TRAIN/TEST SPLITS")
print("-"*80)

try:
    X_train = pd.read_pickle('data/features/X_train_temporal.pkl')
    X_test = pd.read_pickle('data/features/X_test_temporal.pkl')

    print(f"‚úì Training set: {X_train.shape[0]} rows √ó {X_train.shape[1]} features")
    print(f"‚úì Test set: {X_test.shape[0]} rows √ó {X_test.shape[1]} features")
    print(f"\nFeature columns match: {list(X_train.columns) == list(X_test.columns)}")

except Exception as e:
    print(f"‚úó Error: {e}")

# 5. TARGET VARIABLES
print("\n\n5. TARGET VARIABLES")
print("-"*80)

try:
    y_class = pd.read_pickle('data/features/y_classification.pkl')
    y_reg = pd.read_pickle('data/features/y_regression.pkl')

    print(f"‚úì Classification target: {len(y_class)} samples")
    print(f"  ‚Ä¢ High-impact papers: {y_class.sum()} ({y_class.mean()*100:.1f}%)")
    print(f"  ‚Ä¢ Low-impact papers: {(~y_class).sum()} ({(1-y_class.mean())*100:.1f}%)")

    print(f"\n‚úì Regression target: {len(y_reg)} samples")
    print(f"  ‚Ä¢ Min: {y_reg.min():.2f}")
    print(f"  ‚Ä¢ Max: {y_reg.max():.2f}")
    print(f"  ‚Ä¢ Mean: {y_reg.mean():.2f}")
    print(f"  ‚Ä¢ Median: {y_reg.median():.2f}")

except Exception as e:
    print(f"‚úó Error: {e}")

print("\n" + "="*80)
print("INSPECTION COMPLETE")
print("="*80)
